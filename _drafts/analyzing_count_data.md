---
layout: post
title: Analyzing ecological count data
category: blog
tags: 
    - R
    - research
    - statistics
    - distributions
    - hurdle
    - zero-inflated
    - poisson
    - logistic
    - regression
    - anova
---

[GET MY ARTICLE URL!!!]
While working on the same data analysis that I was working on while writing [the article on R and reporting](.....other article), I ran into more statistically oriented problems. I am not a statistician at all. At university I did statistics courses, both general statistics and courses which were more oriented towards ecological research. But given the marks I had and the amount of time passed since then, this in no way qualifies me as a statistician. The article below is therefore more a write-up of my understanding while going over the internet and a few books I had lying around, but is open for improvement. Anyone with a better understanding of it than I is very welcome to leave comments or email me. Your input will be very much appreciated. 

# Goal
What I was working on was data of fish species encountered using a roving diver random swim method on coral reefs. For around 300 species (divided over 4 groups because sampling everything at once was undoable) we had data of counts on 9 different sites, with per site and group 6 samples. There were clear ecological differences between the sites seen through personal observation, and we wanted to analyze if there are any fish species that followed these differences. The ultimate goal was to select a number of species that would then be investigated more in depth and monitored long-term. We therefore only wanted to see if there were species that were significantly more present at some sites than others, so they could possible be an indicated of the ecological differences between those sites.

# Data
All sites had very low numbers of most fish in general, and many species were only rarely encountered. Only a few species were actually common. Because of this, for a lot of species, the count 0 was very over-represented. The data clearly didn't fit normal, Poisson or negative binomial distributions. Also your average sqrt, log and ln transformations didn't help, which makes sense with the high frequencies of 0 counts. So I was left with either checking if my data fitted with different distributions or using non-parametric tests like Kruskal-Wallis (followed by Dunn post-hoc tests).

[GRAPH!!!!]

# Analysis
So I started reading more both in some books and on the internet. As I am using R, I have a million possibilities at my disposal, and there is a lot of discussion about what the right approach is in different situations, as can be seen on the great (but somewhat complex) answers to a simple [question on ResearchGate on post-hoc tests after Kruskal-Wallis](https://www.researchgate.net/post/Which_post_hoc_test_is_best_to_use_after_Kruskal_Wallis_test). This doesn't make the choice on data analysis easier. The choice to how to analyze data isn't nearly as straight-forward as it appeared in the statistical test flowcharts that my teachers showed me at uni (they were a great intro to it though). 

## Zero-inflated models
After reading for a while I came across the zero-inflated (Poisson/negative binomial) distributions. [According to an article by the UCLA: Statistical Consulting Group](http://www.ats.ucla.edu/stat/r/dae/zinbreg.htm) zero inflated models can be used "for modeling count variables with excessive zeros and it is usually [used] for overdispersed count outcome variables. Furthermore, theory suggests that the excess zeros are generated by a separate process from the count values and that the excess zeros can be modeled independently". What this means is that with zero-inflated models two processes are assumed to exist: one causing 0 counts in some of the treatments, and those treatments will always result in a 0 count, while another process causes the rest of the treatments to sometimes show zero counts, but sometimes more. 
In my situation with species abundance, it would mean that some sites some species just don't exist. So this will always result in a 0 count for that species and site. While on other sites, the same species might occur, but doesn't necessary always have to been seen during a survey, so sometimes it will have a 0 count for that site, and sometimes it will show a higher abundance. So there is the process of having the species on the site in the first place, and the process where the species can occur at the site but doesn't necessarily have to be spotted. The mean abundance then depends on the how many of of the individuals are actually there. The zero-inflated model therefore divides the sites into sites that will always show a zero count, and sites that sometimes do, and uses a Poisson (or other) distribution for those sites only.
This seemed to match my situation quite nicely, and some histograms of observed frequency distributions vs expected ones according to different distributions with the same mean and variance showed that zero-inflated models matched my data quite well. 

[GRAPH!!!!]

## Hurdle models
Another set of models you can use are hurdle models, in combination with a Poisson, negative-binomial or exponential model. Basically a Hurdle model creates a "hurdle" between two models. The one model is (often) a binomial model modeling the chance of getting a zero-count. The second model models the actual counts (using a Poisson, negative-binomial or exponential model), excluding the zero-counts. So basically there is a hurdle between the zero-count model and the count model, where samples with a count of less than 1 are put in the binomial model while the other samples are put in the Poisson (or other distribution) model.

To me at first sight it sounded very similar to the zero-inflated models. And indeed it tries to solve the same problem. But [an answer on StackExchange by Hibernating](http://stats.stackexchange.com/a/81854/80734) explains the difference. Both models have a process causing an excess in zero-counts and a process causing the counts>=1. But with the zero-inflated model, the process that causes the counts>=1, can also produce zero-counts. While with the hurdle model all zero-counts come from the process modeled by the binomial model while all other counts are modeled by the Poisson (or other) model. 

The answer on stack exchange explains it with an example of a person choosing whether to buy something, and then how many to buy. With the zero-inflated model you first decide whether to buy the item. If you then decide to buy it, you might still end up with buying nothing, because the item is out of stock for instance. With the hurdle model, if you decide to buy the item, you will always buy it. This is the difference between the two. In my case it means that the choice between the models is determined by the following choice: If we a species is present at a site (and thus potentially we get a count>1), will we always see it (and thus guarantee a count>1) or will there still be the option of not seeing it (and thus having the species present might still result in a 0-count)? I think this is not such a hard choice. If a species is uncommon at a site, but does occur there, we might still not find it because the fish is out of our visual range for instance. So there might still be zero-counts, even if the species is present. The only situation that I can think of where a hurdle model might make sense for analyzing ecological count data is with large schooling nomadic species. Today the might be somewhere else and so you are guaranteed to not see them, while tomorrow the school might be at your site and then you are guaranteed to see them.

## Presence-absence vs counts
These models got me thinking though. I am comparing species counts between sites where for some sites a species is never seen at all, resulting in high 0-counts. And to compensate for that I am using zero-inflated models. But isn't there a simpler way? Basically the zero-inflated models are asking two different questions:
- What is the chance of (not) encountering a species in a sample, and does that differ between sites?
- If the species is present in the area, is there a difference between sites in the mean abundance.

This sounds and awful lot like question 1 is a logistic problem, while only the second one is an actual count data question. Instead of desperately trying to find a distribution that matches my data, shouldn't I split the question into two:
- Are there species that occur more often on some sites than on others?
- Are there species that, when present, occur in higher numbers on some sites than on others?

This is a lot easier to analyze: I convert my count data first into presence-absence data and analyze the chance of encountering a species in a sample, and analyze this with an analysis of variance from a logistic regression with the site as grouping variable. 
Secondly, for each species, I only take those sites where the species actually occurs (so max(count)>0). This throws all the sites with only zero counts out. And then I analyze the count data over those samples/sites.
